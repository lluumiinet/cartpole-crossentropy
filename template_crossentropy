import numpy as np


def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):
    reward_threshold = np.percentile(rewards_batch, percentile)

    elite_states = []
    elite_actions = []

    for i in range(len(rewards_batch)):
        if rewards_batch[i] >= reward_threshold:
            elite_states.extend(states_batch[i])
            elite_actions.extend(actions_batch[i])

    return elite_states, elite_actions


def update_policy(elite_states, elite_actions, n_states, n_actions):
    counts = np.zeros((n_states, n_actions), dtype=np.float64)

    for s, a in zip(elite_states, elite_actions):
        counts[s, a] += 1

    new_policy = np.zeros_like(counts)

    for s in range(n_states):
        total = np.sum(counts[s])
        if total > 0:
            new_policy[s] = counts[s] / total
        else:
            new_policy[s] = 1.0 / n_actions

    return new_policy


def generate_session(env, policy, t_max=int(1e4)):
    states, actions = [], []
    total_reward = 0.0

    s, _ = env.reset()

    for t in range(t_max):
        a = np.random.choice(len(policy[s]), p=policy[s])
        new_s, r, done, truncated, _ = env.step(a)

        states.append(s)
        actions.append(a)
        total_reward += r

        s = new_s
        if done or truncated:
            break

    return states, actions, total_reward
